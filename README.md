# Multi-Agent Framework for FOMC Simulation

Welcome to the Fedsight AI multi-agent simulation system, developed by the Duke University Capstone Team in collaboration with BNY Mellon. Powered by [crewAI](https://crewai.com), this framework is designed to emulate the Federal Open Market Committee (FOMC) decision-making process using large language models (LLMs). Our system enhances the prediction and interpretability of federal funds rate decisions, supporting robust risk management strategies through explainable, agent-based AI simulations.

## Table of Contents

* [Summary](#summary)
* [Motivation & Goals](#motivation--goals)
* [High-Level Overview](#high-level-overview)
* [Installation and Setup](#installation-and-setup)
* [Methodology](#methodology)
* [Investigations & Results](#investigations--results)
* [Connecting Back to Goals](#connecting-back-to-goals)
* [Demo](#demo)
* [References](#references)

## Summary

This project simulates the FOMC using a multi-agent system comprised of LLM-powered agents that reflect diverse FOMC personas. By combining structured (e.g., inflation rates, treasury yields, political variables) and unstructured (e.g., Beige Book summaries, dot plots, rate probability expectations) data inputs, each agent independently processes information, deliberates in a group discussion, and votes. This end-to-end deliberation process mirrors the real-world FOMC and provides high-fidelity insights into monetary policy decisions.

## Motivation & Goals

BNY Mellon’s risk and investment teams rely on accurate rate forecasts to inform capital allocation, portfolio construction, and strategic planning. However, existing models focus only on prediction outcomes, lacking transparency into how those predictions were made. Our simulation aims to:

* **Predict** the FOMC’s rate decisions using a hybrid of macroeconomic modeling and AI agents.
* **Explain** each prediction with interpretable reasoning generated by LLM-powered agents.
* **Support internal validation and enhancement** of proprietary systems (e.g., Eliza) using this backtestable, modular framework.

## High-Level Overview

The project was developed through iterative model enhancements:

1. **Fedsight AI (Base Model)** – Uses sequential prompting among agents ([`/base`](./base))
2. **Fedsight AI + In-Context Learning** – Adds memory of past decisions and agent-specific reflections ([`/base_simulation`](./base_simulation))
3. **Fedsight AI + Chain of Draft (CoD)** – Enhances reasoning efficiency via minimal-step prompting ([`/chain_of_draft`](./chain_of_draft))

## Installation and Setup

This project uses [UV](https://docs.astral.sh/uv/) for dependency management.

### Requirements

* Python >= 3.10 and < 3.13
* `uv` installed via pip

### Setup Instructions

```bash
pip install uv
pip install -r requirements.txt
crewai install
```

Add API keys (`OPENAI_API_KEY`, `DEEPSEEK_API_KEY`, etc.) to your `.env` file.

### Running the Project

From the `bny_capstone_crew/` directory:

```bash
$ crewai run
```

This command launches a simulation that generates a `report.md` file summarizing agent behavior and decision outcomes.

### Backtesting a Meeting

To simulate multiple meetings with automated evaluation:

1. Update `crew.py` and `automated_metrics.py` with the specific `meeting_date` and `correct_vote`.
2. Make the script executable:

```bash
$ chmod +x run_crew.sh
```

3. Run simulations:

```bash
$ ./run_crew.sh
```

Results are stored in `results.txt` and per-run JSON summaries for transparency.

## Methodology

### 1. Quantitative Modeling and Qualitative Framework as Baseline

We first developed a baseline Ordinal Random Forest model as an industry comparator found in ([`/state_of_art_model`](./state_of_art_model))

* **Features:** CPI, PCE, VIX, TB3M, TB6M, M2, unemployment rate, GDP (Brave-Butters-Kelley), political control, prior rate change, etc.
* **Accuracy:** 62.5% on 2023–2024 meetings
* **Limitation:** No interpretability or natural language explanation

We also used MiniFed by Seok et al. as a baseline but was restricted to 2018 for their test set as Tealbook A releases 5 years after the meeting.

### 2. LLM-Based Multi-Agent Simulation

Agents represent FOMC decision-maker personas, such as Central Policymakers, Academic Balancers, and Regional Pragmatists as discussd in Clustering.

* **Structured Inputs:** Economic indicators, FedWatch probabilities
* **Unstructured Inputs:** Beige Book excerpts, dot plot summaries, historical meeting data
* **Agent Roles:**

  * Analyst (interprets market expectations)
  * Economist (generates potential policy paths)
  * Clustered agents (deliberate, vote, and reflect)

### 3. Clustering

To ensure realistic yet efficient simulation:

* Clustered FOMC members using: political alignment, tenure, regional focus, hawkishness, inflation vs. labor market priority
* Resulting personas: Central Policymaker, Academic Balancer, Regional Pragmatist

#### Here are three consolidated FOMC voting members that encapsulate the personalities and decision-making patterns of the original 12 members:

##### 1. Chair Jerome Powell (Consensus Leader)
- **Role:** Chair of the Federal Open Market Committee
- **Goal:** Ensure monetary policy aligns with long-term economic stability, balancing inflation control and labor market resilience.
- **Backstory:** Powell has led the Fed through economic crises, including COVID-19 and the Great Inflation Reversal. He balances aggressive inflation control (Volcker-style) with employment protection (Bernanke-style).
- **Decision Factors:** Beige Book insights, inflation risks, labor market trends.
- **Likely Vote:** Leans toward consensus but prefers stability; cautious on rate cuts unless inflation is clearly under control.

##### 2. Vice Chair John Williams (Data-Driven Economist)
- **Role:** Vice Chair of the Federal Reserve
- **Goal:** Use quantitative models and historical Fed policy cycles to guide interest rate decisions.
- **Backstory:** Williams emphasizes empirical data, referencing global central banks and past rate cycles. He values inflation persistence metrics and soft-landing strategies (1990s).
- **Decision Factors:** CPI/PCE inflation data, global monetary trends, employment softness.
- **Likely Vote:** Supports cuts if inflation data trends downward and unemployment worsens.

##### 3. Regional & Regulatory Representative (Economic Field Perspective)
- **Role:** Represents regional economies, financial stability, and banking system health.
- **Goal:** Balance the needs of labor markets, small businesses, and financial institutions.
- **Backstory:** Inspired by Bostic, Barkin, Barr, and Kugler, this representative monitors the banking sector (post-2008 reforms), regional labor markets (job trends), and global competitiveness (capital flows).
- **Decision Factors:** Unemployment spikes, credit liquidity concerns, global rate adjustments.
- **Likely Vote:** Pushes for cuts if regional economic strain or banking liquidity risks emerge.

##### How These Three Capture the Original 12:
- Powell represents the stabilizers (himself, Bowman, Daly, Waller).
- Williams represents the data-driven economists (Cook, Jefferson, Kugler).
- The third agent integrates regional perspectives, financial stability concerns, and global trends (Bostic, Barkin, Barr, and others).
*This setup ensures the voting dynamics still reflect the broader FOMC’s policy inclinations.*

### 4. In-Context Learning & Chain of Draft

**In-Context Learning** stores previous agent votes, rationales, and reflections, improving memory retention and decision consistency.

**Chain of Draft** minimizes token usage and improves clarity by constraining reasoning to \~30-word steps. It reduces verbosity without compromising deliberative quality.

## Investigations & Results

### Evaluation Metrics

#### Average Rate Change Accuracy
Whether the model correctly predicts the overall rate decision for each meeting.

<p align="center">
<img src="https://latex.codecogs.com/svg.image?\bg_black\color{white}$$%5Ctext%7BAverage&space;Rate&space;Change&space;Accuracy%7D=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi=1%7D%5E%7BN%7D%5Cmathbf%7B1%7D%5Cleft(%5Chat%7B%5Ctext%7BVote%7D%7D_i=%5Ctext%7BVote%7D%5E*_i%5Cright)$$" />
</p>

#### Average Individual Voting Accuracy  
Whether each agent correctly predicts the true rate decision in each meeting.

<p align="center">
<img src="https://latex.codecogs.com/svg.image?\bg_black\color{white}$$%5Ctext%7BAverage&space;Individual&space;Voting&space;Accuracy%7D=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi=1%7D%5E%7BN%7D%5Cleft(%5Cfrac%7B1%7D%7BK%7D%5Csum_%7Bk=1%7D%5E%7BK%7D%5Cmathbf%7B1%7D%5Cleft(%5Chat%7B%5Ctext%7BVote%7D%7D_%7Bi,k%7D=%5Ctext%7BVote%7D%5E*_i%5Cright)%5Cright)$$" />
</p>

#### Average Voting Stability  
Evaluates the consistency of model predictions for individual agent votes across simulation runs for each meeting.

<p align="center">
<img src="https://latex.codecogs.com/svg.image?\bg_black\color{white}$$%5Ctext%7BAverage&space;Voting&space;Stability%7D=%5Cfrac%7B1%7D%7BNJK%7D%5Csum_%7Bi=1%7D%5E%7BN%7D%5Csum_%7Bj=1%7D%5E%7BJ%7D%5Csum_%7Bk=1%7D%5E%7BK%7D%5Cmathbf%7B1%7D%5Cleft(%5Cwidehat%7B%5Ctext%7BVote%7D%7D_%7Bi,j,k%7D=%5Cwidehat%7B%5Ctext%7BVote%7D%7D_%7Bi,k%7D%5E%7B%5Ctext%7Bmode%7D%7D%5Cright)$$" />
</p>

####  Reasoning Similarity
Evaluate the cosine similarity between the embeddings of the generated statement compared to the actual FOMC statement.

<p align="center">
<img src="https://latex.codecogs.com/svg.image?\bg_black\color{white}$$%5Ctext%7BAverage%20Similarity%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En%5Cfrac%7BS_i%20%5Ccdot%20S_%7B%5Ctext%7Bactual%7D%7D%7D%7B%5C%7CS_i%5C%7C%5C%2C%5C%7CS_%7B%5Ctext%7Bactual%7D%7D%5C%7C%7D$$" />
</p>


#### Token Usage
How many tokens do we save to optimize speed and lower costs?

<p align="center">
<img src="https://latex.codecogs.com/svg.image?\bg_black\color{white}$$%5Ctext%7BTotal%20Tokens%7D%20=%20%5Ctext%7BPrompt%20Tokens%7D%20%2B%20%5Ctext%7BCompletion%20Tokens%7D$$" />
</p>

#### Mean Absolute Error (MAE)
How far off on average are the model's incorrect predictions?

<p align="center">
<img src="https://latex.codecogs.com/svg.image?\bg_black\color{white}$$%5Ctext%7BMAE%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En%5Cleft%7C%20y_i%20-%20%5Chat%7By%7D_i%20%5Cright%7C$$" />
</p>


Evaluated over 16 meetings (2023–2024), with 5 runs per meeting.

### Key Results + Interpretation

![Key Reults](https://github.com/user-attachments/assets/893c8c25-bff5-4858-9886-77d71bdb39c6)

#### Fedsight + Chain of Draft (CoD) (Best Performing Model)

* **Prediction Accuracy:** 93.75%
* **Individual Accuracy:** \~90% per agent
* **Voting Stability:** >85%
* **Reasoning Similarity:** \~75%
* **MAE:** 0.015%
* **Token Usage:** Reduced by 25.6%
* **Comment:** Best performing model across all metrics.
* **Folder:** [`/chain_of_draft`](./chain_of_draft)

### Industry Benchmark Comparison

* **Ordinal Forest (2024):** 62.5%
* **MiniFed (2018):** 75%
* **Fedsight + CoD:** 100% on same 2018 test set

![Comparison](https://github.com/user-attachments/assets/44846e28-6706-4e7d-bbcc-a789233da9bf)


These results show that our framework not only predicts more accurately but also offers richer interpretability and stronger alignment with actual FOMC communications. Specifically:

* **Accuracy:** The Chain of Draft (CoD) model significantly outperformed both academic benchmarks and traditional machine learning baselines, demonstrating its ability to generalize across macroeconomic cycles and decision contexts.
* **Interpretability:** Unlike black-box models, each agent produces transparent, structured explanations rooted in both quantitative indicators and narrative sources like the Beige Book.
* **Stability:** Consistent predictions across repeated runs indicate that our simulation is not heavily influenced by LLM randomness—critical for building user trust.
* **Faithfulness to FOMC Rationale:** Reasoning similarity scores show that our system's justifications align semantically with actual statements, revealing a deep understanding of FOMC communication style and themes.
* **Efficiency:** By reducing token usage through Chain of Draft prompting, we not only cut computational cost but also streamline model outputs for integration into downstream tools (e.g., dashboards, summaries).

## Connecting Back to Goals

Our goal was to move beyond static, opaque prediction systems toward a transparent, modular simulation of FOMC decision-making. The results confirm that Fedsight AI achieves this across multiple dimensions:

* **Predictive Power:** Achieves state-of-the-art accuracy on current and historical test sets, outperforming traditional models used in industry and academia.
* **Interpretability:** Every agent decision includes a rationale that can be audited, traced back to inputs, and compared with FOMC communications—key for internal validation.
* **Stability & Reliability:** High voting stability ensures that results are repeatable and dependable.
* **Integration Potential:** The model is built for easy incorporation into platforms like BNY’s Eliza, allowing analysts to test custom scenarios, add proprietary data, or generate explainable FOMC-style reports.
* **Scalability:** Thanks to its modularity and token-efficient design, Fedsight AI can be extended to other central bank settings or adapted for real-time forecasting.

Ultimately, our team helps procide a balance of the following: **accuracy meets interpretability**, and **simulation enables foresight**.

## Demo
We provide a demo in [`/demo](./demo)
Details about the tech stack are below:

### Backend
- **Python + FastAPI**: Web server with WebSocket support and REST API
- **CrewAI**: Multi-agent framework simulating FOMC discussions 
- **OpenAI**: GPT-4o and GPT-4o-mini for agent intelligence
- **Data Storage**: File-based (PDFs/CSVs) and SQLite for memory

###  Frontend
- **React + Next.js**: Client-side framework with hooks and Context API
- **WebSockets**: Real-time communication with CrewAI cli output with frontend 

The application creates an AI-powered simulation dashboard of Federal Reserve meetings to analyze economic data and predict monetary policy decisions.

## References

1. Li, P., Castelo, N., Katona, Z., & Sarvary, M. (2024). *Frontiers: Determining the validity of large language models for automated perceptual analysis.* Marketing Science, 43(2), 254–266.

2. Xu, S., Xie, W., Zhao, L., & He, P. (2025). *Chain of Draft: Thinking Faster by Writing Less.* arXiv preprint. [arXiv:2502.18600](https://arxiv.org/abs/2502.18600)

3. Seok, S., Wen, S., Yang, Q., Feng, J., & Yang, W. (2024). *MiniFed: Integrating LLM-based Agentic-Workflow for Simulating FOMC Meeting.* arXiv preprint. [arXiv:2410.18012](https://arxiv.org/abs/2410.18012)

4. Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). *Generative agents: Interactive simulacra of human behavior.* In *Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology* (pp. 1–22).

5. Federal Reserve. (n.d.). *FOMC meeting calendars, statements, and minutes.* Retrieved February 2, 2025, from [https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm](https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm)

6. CME Group. (n.d.). *CME FedWatch Tool.* Retrieved February 15, 2025, from [https://www.cmegroup.com/markets/interest-rates/cme-fedwatch-tool.html](https://www.cmegroup.com/markets/interest-rates/cme-fedwatch-tool.html)

7. Tadle, R. C. (2022). *FOMC minutes sentiments and their impact on financial markets.* Journal of Economics and Business, 118, 106021. [https://doi.org/10.1016/j.jeconbus.2021.106021](https://doi.org/10.1016/j.jeconbus.2021.106021)

8. Ruman, A. M. (2023). *A comparative textual study of FOMC transcripts through inflation peaks.* Journal of International Financial Markets, Institutions and Money, 87, 101822. [https://doi.org/10.1016/j.intfin.2023.101822](https://doi.org/10.1016/j.intfin.2023.101822)

9. Yoon, J., & Fan, J. (2024). *Forecasting the direction of the Fed's monetary policy decisions using random forest.* Journal of Forecasting, 43(7), 2848–2859. [https://doi.org/10.1002/for.3144](https://doi.org/10.1002/for.3144)
